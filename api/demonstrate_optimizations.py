#!/usr/bin/env python3
"""
Script para demonstrar as otimizaÃ§Ãµes implementadas
"""

import time
import os
from src.services.predict_service import PredictionService

def demonstrate_optimizations():
    """
    Demonstra as otimizaÃ§Ãµes implementadas no carregamento do modelo
    """
    print("=== DemonstraÃ§Ã£o das OtimizaÃ§Ãµes ===\n")
    
    # Limpar cache
    PredictionService.clear_model_cache()
    
    # Dados de teste
    test_data = {
        "Pclass": 1,
        "Sex": "female", 
        "Age": 25.0,
        "SibSp": 0,
        "Parch": 0,
        "Fare": 100.0,
        "Embarked": "S"
    }
    
    print("ğŸš€ OTIMIZAÃ‡ÃƒO 1: Movendo inicializaÃ§Ã£o para fora da funÃ§Ã£o Lambda")
    print("   âœ… Implementado: PassengerController instanciado globalmente")
    print("   ğŸ“ˆ BenefÃ­cio: Modelo carregado apenas no cold start, nÃ£o a cada requisiÃ§Ã£o")
    
    print("\nğŸš€ OTIMIZAÃ‡ÃƒO 2: Lazy Loading + Cache de Modelo")
    print("   âœ… Implementado: Cache em nÃ­vel de classe para reutilizaÃ§Ã£o")
    print("   ğŸ“ˆ BenefÃ­cio: InstÃ¢ncias subsequentes reutilizam modelo jÃ¡ carregado")
    
    print("\nğŸš€ OTIMIZAÃ‡ÃƒO 3: Fallback inteligente de formatos")
    print("   âœ… Implementado: Tentativa automÃ¡tica pickle -> joblib")
    print("   ğŸ“ˆ BenefÃ­cio: Usa o formato mais rÃ¡pido disponÃ­vel")
    
    print("\nğŸ“Š TESTE PRÃTICO:")
    
    # Teste 1: Primeiro carregamento
    print("\n1. Primeiro carregamento (cold start):")
    start_time = time.time()
    service1 = PredictionService(model_name="model", method="pickle")
    prediction1 = service1.predict(test_data)
    first_time = time.time() - start_time
    print(f"   â±ï¸  Tempo total: {first_time:.4f}s")
    print(f"   ğŸ¯ PrediÃ§Ã£o: {prediction1:.4f}")
    
    # Teste 2: Segundo serviÃ§o (cache hit)
    print("\n2. Segunda instÃ¢ncia (cache hit):")
    start_time = time.time()
    service2 = PredictionService(model_name="model", method="pickle")
    prediction2 = service2.predict(test_data)
    second_time = time.time() - start_time
    print(f"   â±ï¸  Tempo total: {second_time:.4f}s")
    print(f"   ğŸ¯ PrediÃ§Ã£o: {prediction2:.4f}")
    
    # Teste 3: ReutilizaÃ§Ã£o da mesma instÃ¢ncia
    print("\n3. ReutilizaÃ§Ã£o da instÃ¢ncia:")
    start_time = time.time()
    prediction3 = service2.predict(test_data)
    third_time = time.time() - start_time
    print(f"   â±ï¸  Tempo total: {third_time:.4f}s")
    print(f"   ğŸ¯ PrediÃ§Ã£o: {prediction3:.4f}")
    
    # AnÃ¡lise
    print(f"\nğŸ“ˆ ANÃLISE DE PERFORMANCE:")
    improvement_cache = ((first_time - second_time) / first_time) * 100
    improvement_reuse = ((first_time - third_time) / first_time) * 100
    
    print(f"   ğŸ’¡ Melhoria com cache: {improvement_cache:.1f}%")
    print(f"   ğŸ’¡ Melhoria com reutilizaÃ§Ã£o: {improvement_reuse:.1f}%")
    
    if first_time > 30:
        print("   âš ï¸  ALERTA: Primeiro carregamento ainda > 30s")
        print("   ğŸ’¡ RECOMENDAÃ‡ÃƒO: Considere treinar modelo menor ou usar modelo prÃ©-compilado")
    elif first_time > 5:
        print("   âš ï¸  ATENÃ‡ÃƒO: Primeiro carregamento > 5s")
        print("   ğŸ’¡ SUGESTÃƒO: Modelo pode ser otimizado ainda mais")
    else:
        print("   âœ… Performance do primeiro carregamento aceitÃ¡vel")
    
    if second_time < 1:
        print("   âœ… Cache funcionando excelentemente")
    elif second_time < 5:
        print("   âœ… Cache funcionando bem")
    else:
        print("   âš ï¸  Cache pode precisar de ajustes")
    
    print(f"\nğŸ“‹ RESUMO DAS OTIMIZAÃ‡Ã•ES IMPLEMENTADAS:")
    print("   1. âœ… Controller global (evita recarga a cada requisiÃ§Ã£o)")
    print("   2. âœ… Lazy loading (modelo carregado sÃ³ quando necessÃ¡rio)")
    print("   3. âœ… Cache de classe (reutilizaÃ§Ã£o entre instÃ¢ncias)")
    print("   4. âœ… Fallback inteligente (tenta formato mais rÃ¡pido primeiro)")
    print("   5. âœ… Logs detalhados (para debugging de performance)")
    
    print(f"\nğŸ’¡ PARA AMBIENTE LAMBDA:")
    print("   â€¢ Cold start: ~{:.2f}s (primeira requisiÃ§Ã£o apÃ³s deploy)".format(first_time))
    print("   â€¢ Warm start: ~{:.2f}s (requisiÃ§Ãµes subsequentes)".format(max(second_time, third_time)))
    print("   â€¢ Economia de tempo por requisiÃ§Ã£o: {:.2f}s".format(first_time - min(second_time, third_time)))

if __name__ == "__main__":
    demonstrate_optimizations()
